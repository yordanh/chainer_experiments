{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, Variable, optimizers, serializers, utils\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(Chain):\n",
    "    \n",
    "    def __init__(self, input_channel, output_channel, filter_size, mid_units, n_units, n_label):\n",
    "        super(SimpleCNN, self).__init__(\n",
    "            conv1 = L.Convolution2D(input_channel, output_channel, (filter_size, filter_size)),\n",
    "            l1    = L.Linear(mid_units, n_units),\n",
    "            l2    = L.Linear(n_units,  n_label),\n",
    "        )\n",
    "    \n",
    "    #Classifier\n",
    "    def __call__(self, x):\n",
    "        h1 = F.max_pooling_2d(F.relu(self.conv1(x)), (2,2))\n",
    "        h2 = F.dropout(F.relu(self.l1(h1)))\n",
    "        y = self.l2(h2)\n",
    "        return y\n",
    "\n",
    "#     def forward(self, x, t, train=True):\n",
    "#         h1 = F.max_pooling_2d(F.relu(self.conv1(x)), 3)\n",
    "#         h2 = F.dropout(F.relu(self.l1(h1)), train=train)\n",
    "#         y = self.l2(h2)\n",
    "#         return F.softmax_cross_entropy(y, t), F.accuracy(y, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Procedure definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from collections import defaultdict\n",
    "import six\n",
    "import sys\n",
    "import chainer\n",
    "import chainer.links as L\n",
    "from chainer import optimizers, cuda, serializers\n",
    "import chainer.functions as F\n",
    "import argparse\n",
    "from collections import namedtuple, defaultdict, deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading from http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz...\n",
      "Downloading from http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz...\n",
      "Downloading from http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz...\n",
      "Downloading from http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz...\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "train, test = chainer.datasets.get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python2.7/site-packages/chainer/optimizers/ada_grad.py:50: RuntimeWarning: invalid value encountered in sqrt\n",
      "  param.data -= lr * grad / (numpy.sqrt(h) + eps)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e94300e18102>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;31m#         stats[\"accuracy\"].append(float((ys.data.argmax(1) == ys).sum() / batchsize))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "gpu = -1\n",
    "n_epoch = 10\n",
    "batchsize = 128\n",
    "mnunits = 1690\n",
    "nuits = 100\n",
    "\n",
    "filter_size = 4\n",
    "n_label = 10\n",
    "input_channel = 1\n",
    "output_channel = 10\n",
    "\n",
    "model = L.Classifier(SimpleCNN(input_channel, output_channel, filter_size, mnunits, nuits, n_label))\n",
    "# model = SimpleCNN(input_channel, output_channel, filter_size, mnunits, nuits, n_label)\n",
    "\n",
    "xp = np\n",
    "if gpu >= 0:\n",
    "    cuda.check_cuda_available()\n",
    "    cuda.get_device(gpu).use()\n",
    "    model.to_gpu()\n",
    "    xp = cuda.cupy\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer = optimizers.AdaGrad()\n",
    "optimizer.setup(model)\n",
    "\n",
    "# Learning loop\n",
    "stats = defaultdict(lambda: deque(maxlen=25))\n",
    "for epoch in range(1, n_epoch + 1):\n",
    "\n",
    "    print 'epoch', epoch, '/', n_epoch\n",
    "    \n",
    "    # training)\n",
    "    train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
    "    test_iter = chainer.iterators.SerialIterator(test, batchsize, repeat=False, shuffle=False)\n",
    "\n",
    "    for itr, batch in enumerate(train_iter):\n",
    "        \n",
    "        xs = xp.array([datum[0][None, :].reshape(1,28,28) for datum in batch])\n",
    "        ts = xp.array([datum[1] for datum in batch])\n",
    "\n",
    "#         print(xs.shape)\n",
    "#         print(ts.shape)\n",
    "        \n",
    "#         ys = model(xs)\n",
    "        \n",
    "#         loss = F.softmax_cross_entropy(ys, ts)\n",
    "        \n",
    "        optimizer.update(model, xs, ts)\n",
    "        \n",
    "        stats[\"loss\"].append(float(loss.data))\n",
    "#         stats[\"accuracy\"].append(float((ys.data.argmax(1) == ys).sum() / batchsize))\n",
    "\n",
    "        if itr % 300 == 0:\n",
    "            print(\"; \".join(\"%s: %s\" % (k, np.mean(vs)) for k, vs in stats.items()))\n",
    "\n",
    "    sys.stdout.flush()\n",
    "\n",
    "print 'save the model'\n",
    "serializers.save_npz('./model/pn_classifier_cnn.model', model)\n",
    "print 'save the optimizer'\n",
    "serializers.save_npz('./model/pn_classifier_cnn.state', optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
